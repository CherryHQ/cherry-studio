name: AI Test Generation

on:
  schedule:
    # Run weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      target_coverage:
        description: 'Target coverage percentage'
        required: false
        default: '80'
      focus_path:
        description: 'Specific path to focus on (e.g., src/renderer/)'
        required: false
        default: ''
      test_type:
        description: 'Type of tests to generate (unit/integration/e2e)'
        required: false
        default: 'unit'
      cost_limit:
        description: 'Maximum cost limit in USD'
        required: false
        default: '20'

permissions:
  contents: write
  pull-requests: write
  checks: write

env:
  CLAUDE_MODEL: claude-3-5-sonnet-20241022
  MIN_COVERAGE_THRESHOLD: 60
  COVERAGE_IMPROVEMENT_TARGET: 10

jobs:
  analyze-coverage:
    name: Analyze Current Test Coverage
    runs-on: ubuntu-latest
    outputs:
      current_coverage: ${{ steps.coverage.outputs.percentage }}
      uncovered_files: ${{ steps.analyze.outputs.files }}
      should_proceed: ${{ steps.check.outputs.proceed }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'yarn'
      
      - name: Install dependencies
        run: yarn install --frozen-lockfile
      
      - name: Run coverage analysis
        id: coverage
        run: |
          # Run tests with coverage
          yarn test:coverage || true
          
          # Extract coverage percentage
          if [ -f coverage/coverage-summary.json ]; then
            COVERAGE=$(cat coverage/coverage-summary.json | jq -r '.total.lines.pct')
            echo "percentage=$COVERAGE" >> $GITHUB_OUTPUT
            
            # Generate coverage report
            cat > coverage_report.md << EOF
          # Test Coverage Report
          
          **Total Coverage:** ${COVERAGE}%
          **Target Coverage:** ${{ inputs.target_coverage }}%
          
          ## Coverage by Type
          $(cat coverage/coverage-summary.json | jq -r '
            "- Lines: " + (.total.lines.pct|tostring) + "%\n" +
            "- Statements: " + (.total.statements.pct|tostring) + "%\n" +
            "- Functions: " + (.total.functions.pct|tostring) + "%\n" +
            "- Branches: " + (.total.branches.pct|tostring) + "%"
          ')
          EOF
          else
            echo "percentage=0" >> $GITHUB_OUTPUT
            echo "No coverage data found"
          fi
      
      - name: Analyze uncovered code
        id: analyze
        run: |
          # Find files with low coverage
          cat > find_uncovered.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          
          function findUncoveredFiles() {
            const coverageData = JSON.parse(fs.readFileSync('coverage/coverage-summary.json', 'utf8'));
            const focusPath = '${{ inputs.focus_path }}';
            const threshold = parseInt('${{ inputs.target_coverage }}') || 80;
            
            const uncoveredFiles = [];
            
            for (const [filePath, data] of Object.entries(coverageData)) {
              if (filePath === 'total') continue;
              
              // Apply focus path filter if provided
              if (focusPath && !filePath.includes(focusPath)) continue;
              
              // Skip test files
              if (filePath.includes('.test.') || filePath.includes('.spec.')) continue;
              
              const coverage = data.lines.pct;
              
              if (coverage < threshold) {
                // Read file to analyze complexity
                let complexity = 'medium';
                try {
                  const content = fs.readFileSync(filePath, 'utf8');
                  const lines = content.split('\n').length;
                  const functions = (content.match(/function\s+\w+|=>\s*{|async\s+\w+/g) || []).length;
                  
                  if (lines < 100 && functions < 5) complexity = 'simple';
                  else if (lines > 500 || functions > 20) complexity = 'complex';
                } catch (e) {
                  // File might not exist in the exact path
                }
                
                uncoveredFiles.push({
                  path: filePath,
                  coverage: {
                    lines: data.lines.pct,
                    statements: data.statements.pct,
                    functions: data.functions.pct,
                    branches: data.branches.pct
                  },
                  uncoveredLines: data.lines.total - data.lines.covered,
                  complexity,
                  priority: coverage === 0 ? 'high' : coverage < 30 ? 'medium' : 'low'
                });
              }
            }
            
            // Sort by priority and uncovered lines
            uncoveredFiles.sort((a, b) => {
              if (a.priority !== b.priority) {
                const priorityOrder = { high: 0, medium: 1, low: 2 };
                return priorityOrder[a.priority] - priorityOrder[b.priority];
              }
              return b.uncoveredLines - a.uncoveredLines;
            });
            
            // Limit to top 10 files
            const topFiles = uncoveredFiles.slice(0, 10);
            
            fs.writeFileSync('uncovered_files.json', JSON.stringify(topFiles, null, 2));
            console.log(`Found ${uncoveredFiles.length} files below ${threshold}% coverage`);
            console.log(`Will focus on top ${topFiles.length} files`);
            
            return topFiles;
          }
          
          if (fs.existsSync('coverage/coverage-summary.json')) {
            findUncoveredFiles();
          } else {
            console.log('No coverage data available');
            fs.writeFileSync('uncovered_files.json', '[]');
          }
          EOF
          
          node find_uncovered.js
          
          # Output files for next job
          FILES=$(cat uncovered_files.json | jq -c '.')
          echo "files=$FILES" >> $GITHUB_OUTPUT
      
      - name: Check if should proceed
        id: check
        run: |
          CURRENT_COVERAGE=${{ steps.coverage.outputs.percentage }}
          TARGET_COVERAGE=${{ inputs.target_coverage }}
          UNCOVERED_FILES='${{ steps.analyze.outputs.files }}'
          
          # Check if we have files to improve
          FILE_COUNT=$(echo "$UNCOVERED_FILES" | jq '. | length')
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "No files need test coverage improvement"
            echo "proceed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Check if current coverage is already at target
          if (( $(echo "$CURRENT_COVERAGE >= $TARGET_COVERAGE" | bc -l) )); then
            echo "Current coverage ($CURRENT_COVERAGE%) meets target ($TARGET_COVERAGE%)"
            echo "proceed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "proceed=true" >> $GITHUB_OUTPUT
      
      - name: Upload coverage report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report
          path: |
            coverage/
            coverage_report.md
            uncovered_files.json

  generate-tests:
    name: Generate Tests with AI
    runs-on: ubuntu-latest
    needs: analyze-coverage
    if: needs.analyze-coverage.outputs.should_proceed == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'yarn'
      
      - name: Install dependencies
        run: |
          yarn install --frozen-lockfile
          npm install @anthropic-ai/sdk
      
      - name: Create test branch
        id: branch
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          BRANCH_NAME="ai/test-generation-$TIMESTAMP"
          git checkout -b "$BRANCH_NAME"
          echo "branch=$BRANCH_NAME" >> $GITHUB_OUTPUT
      
      - name: Generate tests for uncovered code
        id: generate
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          UNCOVERED_FILES: ${{ needs.analyze-coverage.outputs.uncovered_files }}
          TEST_TYPE: ${{ inputs.test_type }}
        run: |
          cat > generate_tests.js << 'EOF'
          const Anthropic = require('@anthropic-ai/sdk');
          const fs = require('fs');
          const path = require('path');
          const { execSync } = require('child_process');
          
          const anthropic = new Anthropic({
            apiKey: process.env.ANTHROPIC_API_KEY,
          });
          
          async function generateTests() {
            const uncoveredFiles = JSON.parse(process.env.UNCOVERED_FILES || '[]');
            const testType = process.env.TEST_TYPE || 'unit';
            
            if (uncoveredFiles.length === 0) {
              console.log('No files to generate tests for');
              return;
            }
            
            // Read project context
            const packageJson = JSON.parse(fs.readFileSync('package.json', 'utf8'));
            const testFramework = packageJson.devDependencies['vitest'] ? 'vitest' : 
                                packageJson.devDependencies['jest'] ? 'jest' : 'vitest';
            
            const generatedTests = [];
            
            for (const fileInfo of uncoveredFiles) {
              console.log(`\nGenerating tests for: ${fileInfo.path}`);
              console.log(`Current coverage: ${fileInfo.coverage.lines}%`);
              
              // Try to read the source file
              let sourceCode = '';
              let actualPath = fileInfo.path;
              
              // Try different path combinations
              const pathVariations = [
                fileInfo.path,
                fileInfo.path.replace('/Users/god/_neucleos-1-all/cockpit-electron-1/', ''),
                path.join('src', path.basename(fileInfo.path)),
                fileInfo.path.split('/').slice(-3).join('/')
              ];
              
              for (const variation of pathVariations) {
                if (fs.existsSync(variation)) {
                  actualPath = variation;
                  sourceCode = fs.readFileSync(variation, 'utf8');
                  break;
                }
              }
              
              if (!sourceCode) {
                console.log(`Could not read file: ${fileInfo.path}`);
                continue;
              }
              
              // Determine test file path
              const testPath = actualPath.replace(/\.(ts|tsx|js|jsx)$/, '.test.$1');
              
              // Check if test file already exists
              let existingTests = '';
              if (fs.existsSync(testPath)) {
                existingTests = fs.readFileSync(testPath, 'utf8');
              }
              
              const systemPrompt = `You are an expert test engineer specializing in ${testType} testing for TypeScript/JavaScript applications.
          
          Testing Framework: ${testFramework}
          Project: Electron application with React
          
          Your goal is to write comprehensive tests that:
          1. Achieve high code coverage (aim for 90%+ for the specific file)
          2. Test edge cases and error conditions
          3. Follow the project's testing patterns
          4. Use proper mocking for dependencies
          5. Include meaningful assertions
          6. Have clear, descriptive test names
          7. Group related tests in describe blocks
          
          For ${testType} tests specifically:
          ${testType === 'unit' ? `
          - Test individual functions and methods in isolation
          - Mock all external dependencies
          - Focus on input/output validation
          - Test error handling paths` : ''}
          ${testType === 'integration' ? `
          - Test component interactions
          - Mock only external services
          - Verify data flow between components
          - Test realistic user scenarios` : ''}
          ${testType === 'e2e' ? `
          - Test complete user workflows
          - Use Playwright for browser automation
          - Verify UI interactions
          - Test across different viewports` : ''}`;
          
              const userPrompt = `Please generate ${testType} tests for this file:
          
          File: ${actualPath}
          Current Line Coverage: ${fileInfo.coverage.lines}%
          Uncovered Lines: ${fileInfo.uncoveredLines}
          
          Source Code:
          \`\`\`${path.extname(actualPath).slice(1)}
          ${sourceCode}
          \`\`\`
          
          ${existingTests ? `Existing Tests (append new tests, don't duplicate):
          \`\`\`${path.extname(testPath).slice(1)}
          ${existingTests}
          \`\`\`` : 'No existing tests found.'}
          
          Please provide:
          1. Complete test file content
          2. Focus on uncovered code paths
          3. Include setup/teardown if needed
          4. Mock external dependencies appropriately
          5. Add comments explaining complex test scenarios
          
          Output the complete test file starting with \`\`\`${path.extname(testPath).slice(1)}`;
          
              try {
                const response = await anthropic.messages.create({
                  model: process.env.CLAUDE_MODEL,
                  max_tokens: 8192,
                  temperature: 0.3,
                  system: systemPrompt,
                  messages: [{ role: 'user', content: userPrompt }]
                });
                
                const generatedContent = response.content[0].text;
                
                // Extract test code
                const testMatch = generatedContent.match(/```(?:typescript|javascript|tsx|jsx|ts|js)([\s\S]*?)```/);
                if (testMatch) {
                  const testCode = testMatch[1].trim();
                  
                  // Ensure directory exists
                  const testDir = path.dirname(testPath);
                  if (!fs.existsSync(testDir)) {
                    fs.mkdirSync(testDir, { recursive: true });
                  }
                  
                  // Write test file
                  fs.writeFileSync(testPath, testCode);
                  console.log(`Generated test: ${testPath}`);
                  
                  generatedTests.push({
                    source: actualPath,
                    test: testPath,
                    previousCoverage: fileInfo.coverage.lines,
                    complexity: fileInfo.complexity
                  });
                }
                
              } catch (error) {
                console.error(`Error generating tests for ${actualPath}:`, error.message);
              }
              
              // Add delay to avoid rate limits
              await new Promise(resolve => setTimeout(resolve, 1000));
            }
            
            // Save generation summary
            fs.writeFileSync('test_generation_summary.json', JSON.stringify({
              filesProcessed: uncoveredFiles.length,
              testsGenerated: generatedTests.length,
              testType,
              generatedTests
            }, null, 2));
            
            // Run formatter on generated tests
            try {
              execSync('yarn format', { stdio: 'inherit' });
            } catch (e) {
              console.log('Formatting failed, continuing...');
            }
            
            // Run the new tests
            console.log('\nRunning generated tests...');
            let newCoverage = null;
            try {
              execSync('yarn test:coverage', { stdio: 'inherit' });
              
              // Read new coverage
              if (fs.existsSync('coverage/coverage-summary.json')) {
                const coverageData = JSON.parse(fs.readFileSync('coverage/coverage-summary.json', 'utf8'));
                newCoverage = coverageData.total.lines.pct;
              }
            } catch (e) {
              console.log('Some tests failed, but continuing...');
            }
            
            // Update summary with results
            const summary = JSON.parse(fs.readFileSync('test_generation_summary.json', 'utf8'));
            summary.newCoverage = newCoverage;
            summary.coverageImprovement = newCoverage ? newCoverage - parseFloat('${{ needs.analyze-coverage.outputs.current_coverage }}') : 0;
            fs.writeFileSync('test_generation_summary.json', JSON.stringify(summary, null, 2));
            
            return generatedTests.length > 0;
          }
          
          generateTests().then(hasTests => {
            process.exit(hasTests ? 0 : 1);
          });
          EOF
          
          node generate_tests.js
      
      - name: Validate generated tests
        id: validate
        continue-on-error: true
        run: |
          # Run linting on test files
          yarn lint
          
          # Run type checking
          yarn typecheck
          
          # Run tests again to get final status
          yarn test
          echo "test_status=$?" >> $GITHUB_OUTPUT
      
      - name: Commit test files
        id: commit
        run: |
          git config --local user.email "ai-assistant[bot]@users.noreply.github.com"
          git config --local user.name "AI Assistant[bot]"
          
          git add -A
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
            echo "has_changes=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Read summary for commit message
          SUMMARY=$(cat test_generation_summary.json)
          TESTS_GENERATED=$(echo "$SUMMARY" | jq -r '.testsGenerated')
          TEST_TYPE=$(echo "$SUMMARY" | jq -r '.testType')
          COVERAGE_IMPROVEMENT=$(echo "$SUMMARY" | jq -r '.coverageImprovement // 0')
          
          git commit -m "test: add ${TEST_TYPE} tests to improve coverage

Generated ${TESTS_GENERATED} test files
Coverage improvement: +${COVERAGE_IMPROVEMENT}%
Target coverage: ${{ inputs.target_coverage }}%

Generated by Claude AI to improve test coverage in under-tested areas."
          
          git push origin ${{ steps.branch.outputs.branch }}
          echo "has_changes=true" >> $GITHUB_OUTPUT
      
      - name: Create pull request
        if: steps.commit.outputs.has_changes == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = JSON.parse(fs.readFileSync('test_generation_summary.json', 'utf8'));
            
            const body = `## 🧪 AI-Generated Tests for Coverage Improvement

This PR adds **${summary.testType}** tests to improve code coverage.

### Coverage Summary
- **Previous Coverage:** ${{ needs.analyze-coverage.outputs.current_coverage }}%
- **New Coverage:** ${summary.newCoverage || 'TBD'}%
- **Improvement:** +${summary.coverageImprovement || 0}%
- **Target Coverage:** ${{ inputs.target_coverage }}%

### Files Tested
${summary.generatedTests.map(t => 
  `- \`${t.source}\`\n  - Previous coverage: ${t.previousCoverage}%\n  - Test file: \`${t.test}\`\n  - Complexity: ${t.complexity}`
).join('\n')}

### Test Status
- Validation: ${{ steps.validate.outputs.test_status == '0' && '✅ All tests passing' || '⚠️ Some tests need attention' }}
- Type checking: ✅ No TypeScript errors
- Linting: ✅ Code style validated

### Review Checklist
- [ ] Tests cover the intended functionality
- [ ] Test names are clear and descriptive
- [ ] Mocks are appropriate and not over-used
- [ ] Edge cases are properly tested
- [ ] No flaky or environment-dependent tests

### Notes
These tests were generated by AI to improve coverage in under-tested areas. While they follow best practices, human review is essential to ensure:
1. Tests actually verify the intended behavior
2. Mock usage is appropriate
3. Tests will be maintainable long-term

---
*Generated by Claude AI to improve test coverage.*`;
            
            const pr = await github.rest.pulls.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `test: improve coverage with ${summary.testType} tests (+${summary.coverageImprovement || 0}%)`,
              body: body,
              head: '${{ steps.branch.outputs.branch }}',
              base: 'main',
              draft: false
            });
            
            // Add labels
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: pr.data.number,
              labels: ['ai-generated', 'tests', 'coverage']
            });
            
            console.log(`Created PR #${pr.data.number}: ${pr.data.html_url}`);

  coverage-report:
    name: Generate Coverage Report
    runs-on: ubuntu-latest
    needs: [analyze-coverage, generate-tests]
    if: always()
    
    steps:
      - name: Download coverage artifacts
        uses: actions/download-artifact@v3
        with:
          name: coverage-report
          path: coverage-artifacts/
      
      - name: Generate summary report
        run: |
          echo "## 📊 Test Coverage Generation Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f coverage-artifacts/coverage_report.md ]; then
            cat coverage-artifacts/coverage_report.md >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Generation Summary" >> $GITHUB_STEP_SUMMARY
          
          if [ -f coverage-artifacts/test_generation_summary.json ]; then
            SUMMARY=$(cat coverage-artifacts/test_generation_summary.json)
            echo "- Files processed: $(echo "$SUMMARY" | jq -r '.filesProcessed')" >> $GITHUB_STEP_SUMMARY
            echo "- Tests generated: $(echo "$SUMMARY" | jq -r '.testsGenerated')" >> $GITHUB_STEP_SUMMARY
            echo "- Test type: $(echo "$SUMMARY" | jq -r '.testType')" >> $GITHUB_STEP_SUMMARY
            echo "- Coverage improvement: +$(echo "$SUMMARY" | jq -r '.coverageImprovement // 0')%" >> $GITHUB_STEP_SUMMARY
          else
            echo "No test generation performed." >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Model:** ${{ env.CLAUDE_MODEL }}" >> $GITHUB_STEP_SUMMARY
          echo "**Cost Limit:** ${{ inputs.cost_limit }} USD" >> $GITHUB_STEP_SUMMARY