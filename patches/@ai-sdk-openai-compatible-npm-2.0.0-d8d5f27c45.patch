diff --git a/dist/index.d.mts b/dist/index.d.mts
index 332ebc005dbfca852aa18970aebda3127142a8a0..fc0f7b56991c4b9e3fbd250f8fd526ae38890320 100644
--- a/dist/index.d.mts
+++ b/dist/index.d.mts
@@ -22,6 +22,7 @@ declare const openaiCompatibleProviderOptions: z.ZodObject<{
     user: z.ZodOptional<z.ZodString>;
     reasoningEffort: z.ZodOptional<z.ZodString>;
     textVerbosity: z.ZodOptional<z.ZodString>;
+    sendReasoning: z.ZodOptional<z.ZodBoolean>;
 }, z.core.$strip>;
 type OpenAICompatibleProviderOptions = z.infer<typeof openaiCompatibleProviderOptions>;
 
diff --git a/dist/index.d.ts b/dist/index.d.ts
index 332ebc005dbfca852aa18970aebda3127142a8a0..fc0f7b56991c4b9e3fbd250f8fd526ae38890320 100644
--- a/dist/index.d.ts
+++ b/dist/index.d.ts
@@ -22,6 +22,7 @@ declare const openaiCompatibleProviderOptions: z.ZodObject<{
     user: z.ZodOptional<z.ZodString>;
     reasoningEffort: z.ZodOptional<z.ZodString>;
     textVerbosity: z.ZodOptional<z.ZodString>;
+    sendReasoning: z.ZodOptional<z.ZodBoolean>;
 }, z.core.$strip>;
 type OpenAICompatibleProviderOptions = z.infer<typeof openaiCompatibleProviderOptions>;
 
diff --git a/dist/index.js b/dist/index.js
index 045e2e85625fe8a9e8557778a6e6fc0a07135198..90a6848909fbb263ff31d242aa5afc8cce0a7beb 100644
--- a/dist/index.js
+++ b/dist/index.js
@@ -98,7 +98,7 @@ function getOpenAIMetadata(message) {
   var _a, _b;
   return (_b = (_a = message == null ? void 0 : message.providerOptions) == null ? void 0 : _a.openaiCompatible) != null ? _b : {};
 }
-function convertToOpenAICompatibleChatMessages(prompt) {
+function convertToOpenAICompatibleChatMessages({prompt, options}){
   var _a;
   const messages = [];
   for (const { role, content, ...message } of prompt) {
@@ -149,6 +149,7 @@ function convertToOpenAICompatibleChatMessages(prompt) {
       }
       case "assistant": {
         let text = "";
+        let reasoning_text = "";
         const toolCalls = [];
         for (const part of content) {
           const partMetadata = getOpenAIMetadata(part);
@@ -157,6 +158,12 @@ function convertToOpenAICompatibleChatMessages(prompt) {
               text += part.text;
               break;
             }
+            case "reasoning": {
+              if (options.sendReasoning) {
+                reasoning_text += part.text;
+              }
+              break;
+            }
             case "tool-call": {
               toolCalls.push({
                 id: part.toolCallId,
@@ -174,6 +181,7 @@ function convertToOpenAICompatibleChatMessages(prompt) {
         messages.push({
           role: "assistant",
           content: text,
+          reasoning_content: reasoning_text ?? void 0,
           tool_calls: toolCalls.length > 0 ? toolCalls : void 0,
           ...metadata
         });
@@ -264,7 +272,8 @@ var openaiCompatibleProviderOptions = import_v42.z.object({
   /**
    * Controls the verbosity of the generated text. Defaults to `medium`.
    */
-  textVerbosity: import_v42.z.string().optional()
+  textVerbosity: import_v42.z.string().optional(),
+  sendReasoning: import_v4.z.boolean().optional()
 });
 
 // src/chat/openai-compatible-prepare-tools.ts
@@ -428,7 +437,7 @@ var OpenAICompatibleChatLanguageModel = class {
         reasoning_effort: compatibleOptions.reasoningEffort,
         verbosity: compatibleOptions.textVerbosity,
         // messages:
-        messages: convertToOpenAICompatibleChatMessages(prompt),
+        messages: convertToOpenAICompatibleChatMessages({prompt, options: compatibleOptions}),
         // tools:
         tools: openaiTools,
         tool_choice: openaiToolChoice
@@ -464,6 +473,15 @@ var OpenAICompatibleChatLanguageModel = class {
     if (text != null && text.length > 0) {
       content.push({ type: "text", text });
     }
+    if (choice.message.images) {
+      const match1 = image.image_url.url.match(/^data:([^;]+)/);
+      const match2 = image.image_url.url.match(/^data:[^;]*;base64,(.+)$/);
+      content.push({
+        type: 'file',
+        mediaType: match1 ? (match1[1] ?? 'image/jpeg') : 'image/jpeg',
+        data: match2 ? match2[1] : image.image_url.url,
+      })
+    }
     const reasoning = (_a = choice.message.reasoning_content) != null ? _a : choice.message.reasoning;
     if (reasoning != null && reasoning.length > 0) {
       content.push({
@@ -618,6 +636,17 @@ var OpenAICompatibleChatLanguageModel = class {
                 delta: delta.content
               });
             }
+            if (delta.images) {
+              for (const image of delta.images) {
+                const match1 = image.image_url.url.match(/^data:([^;]+)/)
+                const match2 = image.image_url.url.match(/^data:[^;]*;base64,(.+)$/);
+                controller.enqueue({
+                  type: 'file',
+                  mediaType: match1 ? (match1[1] ?? 'image/jpeg') : 'image/jpeg',
+                  data: match2 ? match2[1] : image.image_url.url,
+                });
+              }
+            }
             if (delta.tool_calls != null) {
               for (const toolCallDelta of delta.tool_calls) {
                 const index = toolCallDelta.index;
@@ -779,6 +808,14 @@ var OpenAICompatibleChatResponseSchema = import_v43.z.object({
               arguments: import_v43.z.string()
             })
           })
+        ).nullish(),
+        images: import_v43.z.array(
+          import_v43.z.object({
+            type: import_v43.z.literal('image_url'),
+            image_url: import_v43.z.object({
+              url: import_v43.z.string(),
+            })
+          })
         ).nullish()
       }),
       finish_reason: import_v43.z.string().nullish()
@@ -808,7 +845,15 @@ var chunkBaseSchema = import_v43.z.object({
               arguments: import_v43.z.string().nullish()
             })
           })
-        ).nullish()
+        ).nullish(),
+        images: import_v43.z.array(
+            import_v43.z.object({
+              type: import_v43.z.literal('image_url'),
+              image_url: import_v43.z.object({
+                url: import_v43.z.string(),
+              })
+            })
+           ).nullish()
       }).nullish(),
       finish_reason: import_v43.z.string().nullish()
     })
@@ -1421,7 +1466,7 @@ var OpenAICompatibleImageModel = class {
         fetch: this.config.fetch
       });
       return {
-        images: response2.data.map((item) => item.b64_json),
+        images: response2.data.map((item) => item.b64_json ?? item.url),
         warnings,
         response: {
           timestamp: currentDate,
@@ -1465,7 +1510,7 @@ var OpenAICompatibleImageModel = class {
   }
 };
 var openaiCompatibleImageResponseSchema = import_v48.z.object({
-  data: import_v48.z.array(import_v48.z.object({ b64_json: import_v48.z.string() }))
+  data: import_v48.z.array(import_v48.z.union([import_v48.z.object({ b64_json: import_v48.z.string() }), import_v48.z.object({ url: import_v48.z.string() })]))
 });
 async function fileToBlob(file) {
   if (file.type === "url") {
diff --git a/dist/index.mjs b/dist/index.mjs
index e03379447a27c5801526e327a0cc8bf95767aafb..f1916ba43859c811b3b03fe5ec7d5c829d9f1aea 100644
--- a/dist/index.mjs
+++ b/dist/index.mjs
@@ -80,7 +80,7 @@ function getOpenAIMetadata(message) {
   var _a, _b;
   return (_b = (_a = message == null ? void 0 : message.providerOptions) == null ? void 0 : _a.openaiCompatible) != null ? _b : {};
 }
-function convertToOpenAICompatibleChatMessages(prompt) {
+function convertToOpenAICompatibleChatMessages({prompt, options}) {
   var _a;
   const messages = [];
   for (const { role, content, ...message } of prompt) {
@@ -131,6 +131,7 @@ function convertToOpenAICompatibleChatMessages(prompt) {
       }
       case "assistant": {
         let text = "";
+        let reasoning_text = "";
         const toolCalls = [];
         for (const part of content) {
           const partMetadata = getOpenAIMetadata(part);
@@ -139,6 +140,12 @@ function convertToOpenAICompatibleChatMessages(prompt) {
               text += part.text;
               break;
             }
+            case "reasoning": {
+              if (options.sendReasoning) {
+                reasoning_text += part.text;
+              }
+              break;
+            }
             case "tool-call": {
               toolCalls.push({
                 id: part.toolCallId,
@@ -156,6 +163,7 @@ function convertToOpenAICompatibleChatMessages(prompt) {
         messages.push({
           role: "assistant",
           content: text,
+          reasoning_content: reasoning_text ?? undefined,
           tool_calls: toolCalls.length > 0 ? toolCalls : void 0,
           ...metadata
         });
@@ -246,7 +254,8 @@ var openaiCompatibleProviderOptions = z2.object({
   /**
    * Controls the verbosity of the generated text. Defaults to `medium`.
    */
-  textVerbosity: z2.string().optional()
+  textVerbosity: z2.string().optional(),
+  sendReasoning: z2.boolean().optional()
 });
 
 // src/chat/openai-compatible-prepare-tools.ts
@@ -412,7 +421,7 @@ var OpenAICompatibleChatLanguageModel = class {
         reasoning_effort: compatibleOptions.reasoningEffort,
         verbosity: compatibleOptions.textVerbosity,
         // messages:
-        messages: convertToOpenAICompatibleChatMessages(prompt),
+        messages: convertToOpenAICompatibleChatMessages({prompt, options: compatibleOptions}),
         // tools:
         tools: openaiTools,
         tool_choice: openaiToolChoice
@@ -455,6 +464,15 @@ var OpenAICompatibleChatLanguageModel = class {
         text: reasoning
       });
     }
+    if (choice.message.images) {
+      const match1 = image.image_url.url.match(/^data:([^;]+)/);
+      const match2 = image.image_url.url.match(/^data:[^;]*;base64,(.+)$/);
+      content.push({
+        type: 'file',
+        mediaType: match1 ? (match1[1] ?? 'image/jpeg') : 'image/jpeg',
+        data: match2 ? match2[1] : image.image_url.url,
+      })
+    }
     if (choice.message.tool_calls != null) {
       for (const toolCall of choice.message.tool_calls) {
         content.push({
@@ -602,6 +620,17 @@ var OpenAICompatibleChatLanguageModel = class {
                 delta: delta.content
               });
             }
+            if (delta.images) {
+              for (const image of delta.images) {
+                const match1 = image.image_url.url.match(/^data:([^;]+)/)
+                const match2 = image.image_url.url.match(/^data:[^;]*;base64,(.+)$/);
+                controller.enqueue({
+                  type: 'file',
+                  mediaType: match1 ? (match1[1] ?? 'image/jpeg') : 'image/jpeg',
+                  data: match2 ? match2[1] : image.image_url.url,
+                });
+              }
+            }
             if (delta.tool_calls != null) {
               for (const toolCallDelta of delta.tool_calls) {
                 const index = toolCallDelta.index;
@@ -763,6 +792,14 @@ var OpenAICompatibleChatResponseSchema = z3.object({
               arguments: z3.string()
             })
           })
+        ).nullish(),
+        images: z3.array(
+          z3.object({
+            type: z3.literal('image_url'),
+            image_url: z3.object({
+              url: z3.string(),
+            })
+          })
         ).nullish()
       }),
       finish_reason: z3.string().nullish()
@@ -1465,7 +1502,7 @@ var OpenAICompatibleImageModel = class {
       fetch: this.config.fetch
     });
     return {
-      images: response.data.map((item) => item.b64_json),
+      images: response.data.map((item) => item.b64_json ?? item.url),
       warnings,
       response: {
         timestamp: currentDate,
@@ -1476,7 +1513,7 @@ var OpenAICompatibleImageModel = class {
   }
 };
 var openaiCompatibleImageResponseSchema = z8.object({
-  data: z8.array(z8.object({ b64_json: z8.string() }))
+  data: z8.array(z8.union([z8.object({ b64_json: z8.string() }), z8.object({ url: z8.string() })]))
 });
 async function fileToBlob(file) {
   if (file.type === "url") {
